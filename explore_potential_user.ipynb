{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 京东JData算法大赛(3): 探索高潜用户的行为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比赛的题目是高潜用户购买意向预测, 那么理解清楚**什么是高潜用户**对于数据分析,特征抽取,以及之后的建立模型有着至关重要的作用.  \n",
    "简单来讲,作为训练集的高潜用户应该具有以下特征:\n",
    "- 必须有购买行为\n",
    "- 对一个商品购买和其他交互行为(浏览,点击,收藏等)时间差应该**多于一天**  \n",
    "  因为根据赛题,我们需要预测未来5天的购买情况,那么如果用户对某商品在同一天完成所有的交互行为(包括购买),  \n",
    "  我们无法从这种交易中指导未来的预测."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么接下来,让我们先尝试找出这些高潜用户,之后对他们的行为做一些数据分析."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 定义文件名\n",
    "ACTION_201602_FILE = \"data_ori/JData_Action_201602.csv\"\n",
    "ACTION_201603_FILE = \"data_ori/JData_Action_201603.csv\"\n",
    "ACTION_201603_EXTRA_FILE = \"data_ori/JData_Action_201603_extra.csv\"\n",
    "ACTION_201604_FILE = \"data_ori/JData_Action_201604.csv\"\n",
    "COMMENT_FILE = \"data/JData_Comment.csv\"\n",
    "PRODUCT_FILE = \"data/JData_Product.csv\"\n",
    "USER_FILE = \"data/JData_User.csv\"\n",
    "NEW_USER_FILE = \"data/JData_User_New.csv\"\n",
    "USER_TABLE_FILE = \"data/user_table.csv\"\n",
    "BUY_USER_LIST_FILE = \"data/buy_user_list.csv\"\n",
    "PROTENTIAL_USER_RECORD = \"data/protential_user_record.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 寻找具有购买记录的用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#　在一个文件中寻找有购买记录的用户－商品对\n",
    "def buy_user_in_batch_data(fname, chunk_size=100000):\n",
    "    reader = pd.read_csv(fname, header=0, iterator=True)\n",
    "    chunks = []\n",
    "    loop = True\n",
    "    while loop:\n",
    "        try:\n",
    "            chunk = reader.get_chunk(chunk_size)[\n",
    "                [\"user_id\", \"sku_id\", \"type\"]]\n",
    "            chunks.append(chunk)\n",
    "        except StopIteration:\n",
    "            loop = False\n",
    "            print(\"Iteration is stopped\")\n",
    "\n",
    "    df_ac = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "    # type = 4, 购买\n",
    "    df_ac = df_ac[df_ac['type'] == 4][[\"user_id\", \"sku_id\"]]\n",
    "\n",
    "    return df_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 找出有购买记录的用户，并写到csv文件\n",
    "def find_buy_user():\n",
    "    df_ac = []\n",
    "    df_ac.append(buy_user_in_batch_data(fname=ACTION_201602_FILE))\n",
    "    df_ac.append(buy_user_in_batch_data(fname=ACTION_201603_FILE))\n",
    "    df_ac.append(buy_user_in_batch_data(fname=ACTION_201603_EXTRA_FILE))\n",
    "    df_ac.append(buy_user_in_batch_data(fname=ACTION_201604_FILE))\n",
    "    \n",
    "    # 将多个子记录合并成一个dataframe\n",
    "    df_ac = pd.concat(df_ac, ignore_index=True)\n",
    "    # 将重复的用户－商品对丢弃\n",
    "    df_ac = df_ac.drop_duplicates()\n",
    "    # 写入文件\n",
    "    df_ac.to_csv(BUY_USER_LIST_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 执行程序\n",
    "find_buy_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在一个文件中寻找与给定的user-item对有关的所有记录\n",
    "def ui_record_in_batch_data(fname, ui_pair, chunk_size=100000):\n",
    "    reader = pd.read_csv(fname, header=0, iterator=True)\n",
    "    chunks = []\n",
    "    loop = True\n",
    "    while loop:\n",
    "        try:\n",
    "            chunk = reader.get_chunk(chunk_size)[\n",
    "                [\"user_id\", \"sku_id\", \"time\", \"type\"]]\n",
    "            chunks.append(chunk)\n",
    "        except StopIteration:\n",
    "            loop = False\n",
    "            print(\"Iteration is stopped\")\n",
    "\n",
    "    df_ac = pd.concat(chunks, ignore_index=True)\n",
    "    \n",
    "    df = []\n",
    "    for index, row in ui_pair.iterrows():\n",
    "        usr_id = row[\"user_id\"]\n",
    "        sku_id = row[\"sku_id\"]\n",
    "\n",
    "        # 寻找与user-item对有关的所有记录\n",
    "        df.append(df_ac[(df_ac[\"user_id\"] == usr_id) &\n",
    "                        (df_ac[\"sku_id\"] == sku_id)])\n",
    "\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply功能函数：根据一个user-item对的所有记录，计算当前是否是高潜用户\n",
    "def more_than_a_day(group):\n",
    "    # 最后一次购买该商品的日期\n",
    "    last_buy_day = max(group[group[\"type\"] == 4][\"date\"])\n",
    "    # 最早与该商品发生交互的日期\n",
    "    earliest_behave_day = min(group[\"date\"])\n",
    "    \n",
    "    # 如果间隔不小于１天，则认为是高潜用户\n",
    "    if (last_buy_day - earliest_behave_day).days > 0:\n",
    "        # 字段potential_flag代表是否是高潜用户\n",
    "        group[\"potential_flag\"] = 1\n",
    "    else:\n",
    "        group[\"potential_flag\"] = 0\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 寻找高潜用户，并将相关行为记录写入文件\n",
    "def find_potential_user():\n",
    "    # 有购买行为的user-item对\n",
    "    ui_pair = pd.read_csv(BUY_USER_LIST_FILE, header=0)\n",
    "\n",
    "    df_ac = []\n",
    "    df_ac.append(ui_record_in_batch_data(ACTION_201602_FILE, ui_pair))\n",
    "    df_ac.append(ui_record_in_batch_data(fname=ACTION_201603_FILE))\n",
    "    df_ac.append(ui_record_in_batch_data(fname=ACTION_201603_EXTRA_FILE))\n",
    "    df_ac.append(ui_record_in_batch_data(fname=ACTION_201604_FILE))\n",
    "\n",
    "    df_ac = pd.concat(df_ac, ignore_index=True)\n",
    "    # 丢弃重复的\n",
    "    df_ac = df_ac.drop_duplicates()\n",
    "    \n",
    "    # 增加日期属性\n",
    "    df_ac['date'] = pd.to_datetime(df_ac['time']).dt.date\n",
    "    df_ac = df_ac.groupby([\"user_id\", \"sku_id\"]).apply(more_than_a_day)\n",
    "    \n",
    "    # 找出高潜用户\n",
    "    df_ac = df_ac[df_ac[\"potential_flag\"] == 1]\n",
    "    # 写入文件\n",
    "    df_ac.to_csv(PROTENTIAL_USER_RECORD, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 执行程序\n",
    "find_potential_user()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
